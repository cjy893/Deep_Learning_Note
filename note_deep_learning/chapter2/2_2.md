# logistic回归

**logistic回归**是一种学习算法,用在监督学习问题中,并且输出的标签为0和1(也就是二元分类)时

## 函数的选择

输入一张图片,特征向量x则是一张图片,我们需要识别这张图片是否含有猫,则需要一个算法给出预测值y,即这张图含有猫的概率.

~~**线性回归函数$y = w^Tx + b$**:~~ 实际上并不是一个很好的算法,因为y的范围应当在0到1之间

所以,***sigmoid函数***是一个很好的选择,可以将y的值映射到0到1之间,那么就可以将线性回归函数整个作为自变量带入到**sigmoid函数**中,即$y = f(z) = \frac{1}{1 + e^{-z}}(z = w^Tx + b)$,当z无限大时，$e^{-z}$无限趋近于零，则y整体会趋近于1，反之则趋近于0，不会有超出0和1范围的风险

## 参数w与b

在进行神经网络编程时，我们通常会把w与参数b分开。一些人会额外设置一个$x_0 = 1$，所以矩阵***X***是一个n + 1维的矩阵，此时$y = σ（θ^Tx）$，在这种约定中，存在一个向量$θ = [θ_0,θ_1,...θ_n]$,$x_0$对应的$θ_0$就起到了b的作用，而其余的参数则起到了w的作用,所以一般来讲我们会将w与b看做独立的参数
